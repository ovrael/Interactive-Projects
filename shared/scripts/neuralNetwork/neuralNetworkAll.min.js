class ActivationFunction { constructor(t, s) { this.function = t, this.derivative = s } } class LossFunction { static onehotIndexTarget(t, s) { if (Array.isArray(t)) return t; let e = t, i = []; for (let r = 0; r < s; r++)i.push(r == e ? 1 : 0); return i } } const ActivationFunctions = { Sigmoid: new ActivationFunction(t => t.map(t => 1 / (1 + Math.exp(-t))), t => t.map(t => t * (1 - t))), Tanh: new ActivationFunction(t => t.map(t => Math.tanh(t)), t => t.map(t => 1 - t * t)), ReLU: new ActivationFunction(t => t.map(t => Math.max(t, 0)), t => t.map(t => t > 0 ? 1 : 0)), SoftMax: new ActivationFunction(t => { let s = Number.MIN_VALUE; for (let e = 0; e < t.length; e++)t[e] > s && (s = t[e]); let i = t.map(t => Math.exp(t - s)), r = i.reduce((t, s) => t + s); return i.map(t => t / r) }, t => { let s = []; for (let e = 0; e < t.length; e++)s.push((1 - t[e]) * t[e]); return s }) }, epsilon = Number.EPSILON, LossFunctions = { Regression: { Difference: function (t, s) { let e = []; for (let i = 0; i < t.length; i++)e.push(t[i] - s[i]); return e }, MeanSquaredError: function (t, s) { let e = []; for (let i = 0; i < t.length; i++)e.push(-.5 * (s[i] - t[i]) * (s[i] - t[i])); return e }, LogLoss: function (t, s) { let e = []; for (let i = 0; i < t.length; i++)e.push(-(s[i] * Math.log(epsilon + t[i]))); return e } }, BinaryClassification: { BinaryCrossEntropy: function (t, s) { let e = []; for (let i = 0; i < t.length; i++)e.push(Math.log(epsilon + t[i]) + (1 - s[i]) * Math.log(1 - t[i] + epsilon)); return e } }, MultiClassification: { CategoricalCrossEntropy: function (t, s) { s = LossFunction.onehotIndexTarget(s, t.length); let e = []; for (let i = 0; i < t.length; i++)e.push(s[i] * Math.log(t[i] + epsilon) - (1 - s[i]) * Math.log(1 - t[i] + epsilon)); return e }, SimpleSubtraction: function (t, s) { s = LossFunction.onehotIndexTarget(s, t.length); let e = []; for (let i = 0; i < t.length; i++)e.push(t[i] - s[i]); return e }, SimpleSubtraction2: function (t, s) { s = LossFunction.onehotIndexTarget(s, t.length); let e = []; for (let i = 0; i < t.length; i++)e.push(s[i] - t[i]); return e } } }; class DataManage { static split(t, s, e) { let i = { trainX: [], trainY: [], testX: [], testY: [] }, r = t.length * (1 - e); for (; t.length > 0;) { let a = Math.floor(Math.random() * t.length), n = t.splice(a, 1)[0], h = s.splice(a, 1)[0]; i.testX.length < r ? Math.random() > .5 ? (i.trainX.push(n), i.trainY.push(h)) : (i.testX.push(n), i.testY.push(h)) : (i.trainX.push(n), i.trainY.push(h)) } return i } } class Weights { constructor(t, s) { this.previous = t, this.current = s, this.data = Array(this.previous); for (let e = 0; e < this.previous; e++) { this.data[e] = Array(this.current); for (let i = 0; i < this.current; i++)this.data[e][i] = random() - .5 } } map(t) { for (let s = 0; s < this.previous; s++)for (let e = 0; e < this.current; e++) { let i = this.data[s][e]; this.data[s][e] = t(i, s, e) } return this } multiply(t) { if (!(t instanceof Weights)) return this.map(s => s * t); if (this.previous !== t.previous || this.current !== t.current) { console.log("Columns and Rows of A must match Columns and Rows of B."); return } return this.map((s, e, i) => s * t.data[e][i]) } } class Layer { constructor(t, s = 0, e) { this.neuronsCount = t, this.biases = [], this.sums = [], this.activations = [], this.derivatives = [], this.errors = [], this.gamma = []; for (let i = 0; i < t; i++)this.biases.push(Math.random() - .5), this.sums.push(0), this.activations.push(0), this.derivatives.push(0), this.errors.push(0), this.gamma.push(0); this.weights = s > 0 ? new Weights(s, t) : null, this.weightsDeltas = s > 0 ? new Weights(s, t) : null, this.activationFunction = e } fillNeurons(t) { if (t.length != this.neuronsCount) { console.error(`Data length (${t.length}) is different than neurons length (${this.neuronsCount})!`); return } for (let s = 0; s < t.length; s++)this.activations[s] = t[s] } sumNeurons(t) { for (let s = 0; s < this.neuronsCount; s++) { this.sums[s] = 0; for (let e = 0; e < t.activations.length; e++)this.sums[s] += t.activations[e] * this.weights.data[e][s]; this.sums[s] += this.biases[s] } } activateNeurons() { this.activations = this.activationFunction.function(this.sums) } computeDerivatives() { this.derivatives = this.activationFunction.derivative(this.activations) } computeGamma(t) { for (let s = 0; s < this.neuronsCount; s++) { this.gamma[s] = 0; for (let e = 0; e < t.neuronsCount; e++)this.gamma[s] += t.gamma[e] * t.weights.data[s][e]; this.gamma[s] *= this.derivatives[s] } } computeWeightsDeltas(t) { for (let s = 0; s < this.weightsDeltas.previous; s++)for (let e = 0; e < this.weightsDeltas.current; e++)this.weightsDeltas.data[s][e] = this.gamma[e] * t.activations[s] } computeWeightsDeltasBatch(t) { for (let s = 0; s < this.weightsDeltas.previous; s++)for (let e = 0; e < this.weightsDeltas.current; e++)this.weightsDeltas.data[s][e] += this.gamma[e] * t.activations[s] } resetWeightsDeltas() { for (let t = 0; t < this.weightsDeltas.previous; t++)for (let s = 0; s < this.weightsDeltas.current; s++)this.weightsDeltas.data[t][s] = 0 } updateWeights(t = .005) { for (let s = 0; s < this.weights.current; s++) { this.biases[s] -= this.gamma[s] * t; for (let e = 0; e < this.weights.previous; e++)this.weights.data[e][s] -= this.weightsDeltas.data[e][s] * t } } } class NeuralNetwork { constructor(t, s = .05) { this.lossFunction = t, this.learningRate = s, this.layers = [], this.layersCount = -1, this.lastTarget = null, this.singleOutput = !1 } compile(t, s = .05) { this.lossFunction = t, this.learningRate = s, this.#a() } addLayer(t, s) { let e = this.layers.length > 0 ? this.layers[this.layers.length - 1].neuronsCount : 0; this.layers.push(new Layer(t, e, s)) } train(t, s, e = .7, i = 100) { if (!this.#b(t, s)) return; this.#a(); let r = DataManage.split(t, s, e), a = Math.floor(i / 10); for (let n = 0; n < i; n++) { let h = 0; for (let l = 0; l < r.trainX.length; l++)this.#c(r.trainX[l]), h -= this.#d(r.trainY[l]), this.#e(), this.lastTarget = r.trainY[l]; h /= r.trainX.length; let o = this.#f(r.testX, r.testY); if (n % a == 0 || n == i - 1) { let u = { Epoch: n, "Train Loss": h, "Test Loss": o[0], "Good Test": o[1], "Test length": r.testX.length }; console.table(u) } } console.info("Training finished"), console.table(this) } trainBatch(t, s, e = 16, i = .7, r = 100) { if (!this.#b(t, s)) return; this.#a(); let a = DataManage.split(t, s, i), n = Math.floor(r / 10); for (let h = 0; h < r; h++) { let l = 0, o = [], u = []; for (let g = 0; g < a.trainX.length; g++) { if (o.push(a.trainX[g]), u.push(a.trainY[g]), o.length == e || g == a.trainX.length - 1) { for (let $ = 1; $ < this.layers.length; $++)this.layers[$].resetWeightsDeltas(); for (let c = 0; c < o.length; c++)this.#c(o[c]), l -= this.#g(u[c]); this.#e(), o = [], u = [] } this.lastTarget = a.trainY[g] } l /= a.trainX.length; let f = this.#f(a.testX, a.testY); if (h % n == 0 || h == r - 1) { let y = { Epoch: h, "Train Loss": l, "Test Loss": f[0], "Good Test": f[1], "Test length": a.testX.length }; console.table(y) } } console.info("Training finished"), console.table(this) } predict(t) { if (Array.isArray(t) || (t = [t]), t.length == this.layers[0].neuronsCount) return this.#c(t), this.layers[this.layersCount - 1].activations } #a() { this.layersCount = this.layers.length, this.singleOutput = 1 == this.layers[this.layersCount - 1].neuronsCount } #b(t, s) { return this.layers.length < 3 ? (console.error("Neural network is too small. It should have at least 3 layers!"), !1) : 0 == t.length ? (console.error("No data to train!"), !1) : t.length != s.length ? (console.error("Data is different size than targets! " + t.length + " != " + s.length), !1) : t[0].length == this.layers[0].neuronsCount || (console.error("Data is different size than first layer of neural network!"), !1) } #c(e) { this.layers[0].fillNeurons(e); for (let i = 1; i < this.layers.length; i++)this.layers[i].sumNeurons(this.layers[i - 1]), this.layers[i].activateNeurons() } #h(r) { let a = 0, n = this.lossFunction(this.layers[this.layers.length - 1].activations, r); this.layers[this.layersCount - 1].computeDerivatives(); for (let h = 0; h < this.layers[this.layers.length - 1].neuronsCount; h++)this.layers[this.layers.length - 1].errors[h] = n[h], this.layers[this.layers.length - 1].gamma[h] = n[h] * this.layers[this.layers.length - 1].derivatives[h], a += n[h]; return this.layers[this.layersCount - 1].computeWeightsDeltas(this.layers[this.layersCount - 2]), a } #d(l) { let o = this.#h(l); for (let u = this.layers.length - 2; u > 0; u--)this.layers[u].computeDerivatives(), this.layers[u].computeGamma(this.layers[u + 1]), this.layers[u].computeWeightsDeltas(this.layers[u - 1]); return o } #i(g) { let $ = 0, c = this.lossFunction(this.layers[this.layers.length - 1].activations, g); this.layers[this.layersCount - 1].computeDerivatives(); for (let f = 0; f < this.layers[this.layers.length - 1].neuronsCount; f++)this.layers[this.layers.length - 1].errors[f] = c[f], this.layers[this.layers.length - 1].gamma[f] = c[f] * this.layers[this.layers.length - 1].derivatives[f], $ += c[f]; return this.layers[this.layersCount - 1].computeWeightsDeltasBatch(this.layers[this.layersCount - 2]), $ } #g(y) { let p = this.#i(y); for (let _ = this.layers.length - 2; _ > 0; _--)this.layers[_].computeDerivatives(), this.layers[_].computeGamma(this.layers[_ + 1]), this.layers[_].computeWeightsDeltasBatch(this.layers[_ - 1]); return p } #e() { for (let m = 1; m < this.layersCount; m++)this.layers[m].updateWeights(this.learningRate) } #f(d, v) { let w = 0, C = 0; if (this.singleOutput) for (let D = 0; D < d.length; D++) { this.#c(d[D]); w = -this.lossFunction(this.layers[this.layers.length - 1].activations, v[D]).reduce((t, s) => t + s, 0); let F = this.layers[this.layers.length - 1].activations[0] > .5 ? 1 : 0; F == v[D] && C++, this.lastTarget = v[D] } else for (let N = 0; N < d.length; N++) { this.#c(d[N]); w = -this.lossFunction(this.layers[this.layers.length - 1].activations, v[N]).reduce((t, s) => t + s, 0); this.#j() == v[N] && C++, this.lastTarget = v[N] } return [w /= d.length, C] } #j() { let T = -1, L = Number.MIN_VALUE, k = this.layers[this.layersCount - 1]; for (let x = 0; x < k.neuronsCount; x++)k.activations[x] > L && (T = x, L = k.activations[x]); return T } } class NeuralNetworkDrawer { constructor(t, s = 60, e = 80) { this.neuralNetwork = t, this.xOffset = s, this.yOffset = e, this.size = 50, rectMode(CENTER) } draw(t, s) { strokeWeight(2), textSize(10), textStyle(NORMAL), textAlign(CENTER, CENTER), push(), textSize(16), text("Target: " + this.neuralNetwork.lastTarget, t - 40, s / 2 - 80), pop(); let e = this.neuralNetwork.layers.length; for (let i = 0; i < e; i++) { let r = .5 * this.xOffset + (t - this.xOffset) * (i / (e - 1)); 0 == i ? (push(), textSize(12), strokeWeight(0), fill(0), text("INPUT", r, 8), pop()) : i == e - 1 ? (push(), textSize(12), strokeWeight(0), fill(0), text("OUTPUT", r, 8), pop()) : (push(), textSize(12), strokeWeight(0), fill(0), text("HIDDEN " + i, r, 8), pop()); let a = this.neuralNetwork.layers[i]; for (let n = 0; n < a.neuronsCount; n++) { let h = .5 * this.yOffset + (s - this.yOffset) * (n / (a.neuronsCount - 1)); if (1 == a.neuronsCount && (h = s / 2), i < e - 1) { let l = this.neuralNetwork.layers[i + 1]; for (let o = 0; o < l.neuronsCount; o++) { let u = .5 * this.xOffset + (t - this.xOffset) * ((i + 1) / (e - 1)), g = .5 * this.yOffset + (s - this.yOffset) * (o / (l.neuronsCount - 1)); 1 == l.neuronsCount && (g = s / 2), strokeWeight(1), line(r, h, u, g) } } strokeWeight(1), fill(0), rect(r, h, this.size, this.size), line(r, h, r, h + 35), rect(r, h + 35, this.size, 12), push(), strokeWeight(0), fill(50, 150, 50), text("S: " + a.sums[n].toFixed(2), r, h - 17), fill(150, 150, 50), text("A: " + a.activations[n].toFixed(2), r, h - 5), fill(50, 150, 250), text("D: " + a.derivatives[n].toFixed(2), r, h + 7), fill(200, 40, 40), text("E: " + a.errors[n].toFixed(2), r, h + 19), fill(150, 40, 200), text("B: " + a.biases[n].toFixed(2), r, h + 35), pop() } } } }